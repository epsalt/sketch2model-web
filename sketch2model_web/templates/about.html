{% extends "boilerplate.html" %}
{% block content %}

<div class="row">
  <div class="col-sm-offset-2 col-sm-8">
    <div class="page-header">
      <h1>About sketch2model</h1>
    </div>
    <h2>The Team</h2>
    <p>
      Sketch2Model was created
      by <a href="https://scibbatical.wordpress.com/">
      Elwyn</a>, <a href="http://www.epsalt.ca"> Evan</a>,
      and <a href="https://mycarta.wordpress.com/"> Matteo</a>.
    </p>
    <p>
      Big shoutouts to <a href="https://twitter.com/kwinkunks">Matt
        Hall</a> with <a href="https://agilescientific.com/"> Agile
        Scientific</a> for organizing the hackathon
        and <a href="https://github.com/ben-bougher">Ben Bougher</a>
        for all the help.
    </p>
    <h2>Further Reading</h2>
    <strong>Articles about sketch2model</strong>
    <ul>
      <li><a href="https://scibbatical.wordpress.com/2016/05/02/sketch2model/">
          An Introduction to sketch2model</a> (Elwyn)
      </li>
      <li>
        <a href="https://scibbatical.wordpress.com/2016/12/10/mild-or-wild/">
          Robustness through Morphological Filtering</a> (Elwyn)
      </li>
      <li>
        <a href="https://mycarta.wordpress.com/2016/05/25/sketch2model-sketch-image-enhancements/">
          sketch2model Image Enhancements</a> (Matteo)
      </li>
      <li>
        <a href="https://mycarta.wordpress.com/2016/07/22/sketch2model-linking-edges-with-mathematical-morphology/">
          Linking Edges with Mathematical Morphology</a> (Matteo)
      </li>
    </ul>
    <strong>sketch2model Code on Github</strong>
    <ul>
      <li>
        <a href="https://github.com/mycarta/sketch2model">
          Python sketch2model image processing algorithm code </a>
      </li>
      <li>
        <a href="https://github.com/epsalt/sketch2model_web">
          Flask code for this website
        </a>
      </li>
    </ul>
    <h2 id="about-sketch2model">The Idea</h2>
    <p>
      The idea behind sketch2model is that a user should be able to
      easily create forward seismic models. Modeling at the speed of
      imagination, allowing seamless transition from idea to synthetic
      seismic section. It should happen quickly enough to be
      incorporated into a conversation. It should happen where
      collaboration happens.</p>
    <p>
      Geophysicists like to model wedges,
      and <a href="http://www.agilegeoscience.com/blog/2011/7/8/tuning-geology.html?rq=wedge">for
      good reasons</a>. However, wedge logic can get lost on
      colleagues. It may not effectively demonstrate the capability of
      seismic data in a given situation. The idea is not to supplant
      that kind of modeling, but to enable a new, lighter kind of
      modeling. Modeling that can easily produce results for twelve
      different depositional scenarios as quickly as they can be
      sketched on a whiteboard.</p>
    <figure>
      <img src="static/overview.png" class="center-block img-responsive" alt="wedges">
      <figcaption>
        <p class="text-muted">
          The skech2model concept: modelling at the speed of
          imagination. Take a sketch (a), turn it into an earth model
          (b), create a forward seismic model (c). Sketch2model takes
          you from a to b.
        </p>
      </figcaption>
    </figure>
    <p>
      We tackled this idea at
      the <a href="http://www.agilegeoscience.com/blog/2015/5/15/canadian-codeshow">2015
      Geoscience Hackathon hosted</a> in Calgary, Alberta
      by <a href="http://www.agilegeoscience.com/">Agile
      Geoscience</a>. A great experience where teams attacked projects
      in geoscience computing over a weekend. The programming language
      of choice for this project is Python, for reasons nicely
      articulated by Agile in
      their <a href="http://www.agilegeoscience.com/blog/2016/4/6/why-python-beats-matlab">blog
      post.</a>
    </p>
    <figure>
      <img src="static/team_photo.jpg" class="center-block img-responsive" alt="the sketch2model team">
      <figcaption>
        <p class="text-muted">
          Collaboration in action. Evan, Matteo, and Elwyn
          (foreground, L to R) work on sketch2model at
          the <a href="http://www.agilegeoscience.com/blog/2015/5/15/canadian-codeshow">2015
          Calgary Geoscience Hackathon.</a> Photo courtesy
          of <a href="https://www.linkedin.com/in/penny-colton-5a652914">Penny
          Colton.</a>
        </p>
      </figcaption>
    </figure>
    <h2 id="objective-for-sketch2model">Objective</h2>
    <p>
      Building something mobile to turn a sketch into a synthetic
      seismic section is a pretty tall order for a weekend. We decided
      to take a shortcut by leveraging an existing project: Agile’s
      online seismic modelling
      package, <a href="https://www.modelr.io/">modelr</a>. The fact
      that modelr works through any web browser (including a
      smartphone) kept things mobile. In addition, modelr’s existing
      functionality allows a user to upload a png image and use it as
      a rock property model. We chose to use a web API to interface
      our code with the web application (as a bonus, our approach
      conveniently fit with the hackathon’s theme of Web). Using
      modelr’s capabilities, our hack was left with the task of
      turning a photo of a sketched geologic section into a png image
      where each geologic body is identified as a different color. An
      image processing project!
    </p>
    <figure>
      <img src="static/whiteboard.png" class="center-block img-responsive" alt="whiteboard examples">
      <figcaption>
        <p class="text-muted">
          Our algorithm needs to be robust enough to handle a variety
          of source images: simple, complex, pencil, marker, paper,
          white board (check out the glare on the bottom left
          image). These are some of the test images we used.
        </p>
      </figcaption>
    </figure>
    <p>
      We aimed to create an algorithm robust enough to handle any
      image of anything a user might sketch while accurately
      reproducing their intent. Marker on whiteboard presents
      different challenges than pencil on paper. Light conditions can
      be highly variable. Sketches can be simple or complex, tidy or
      messy. When user leaves a small gap between two lines of the
      sketch, should the algorithm take the sketch as-is and interpret
      a single body? Or fill the small gap and interpret two separate
      bodies?
    </p>
    <h2 id="approach">Approach</h2>
    <p>
      Matteo has used image processing for
      geoscience <a href="https://mycarta.wordpress.com/category/image-processing-2">before</a>,
      so he landed on an approach for our hack almost instantly:
      binarize to distinguish sketch from background (turn color image
      into
      a <a href="https://en.wikipedia.org/wiki/Binary_image">binary
      image</a>); identify and segregate geobodies; create output
      image with each body colored uniquely.
    </p>
    <figure>
      <img src="static/binarize.png" class="center-block img-responsive" alt="binarization">
      <figcaption>
        <p class="text-muted">
          Taking the image of the original sketch (left) and creating
          a binary image (right).
        </p>
      </figcaption>
    </figure>
    <p>
      Python has functions one can use to binarize a color image, but
      for our applications, the results were very inconsistent. We
      needed a tool that can work for a variety of media in varying
      lighting conditions. Fortunately, Matteo had some tricks up his
      sleeve to precondition the images before binarization. We landed
      on a robust flow that can binarize whatever we throw at it. We
      will add more on this later.
    </p>
    <p>
      Once the image is binarized, each geobody must be automatically
      identified as a unique element. If the sketch were reproduced
      exactly as intended, a segmentation function would do a good
      job. The trouble is that the sketch captured is rarely the same
      as the one intended -- an artist may accidentally leave small
      gaps between sketch lines, or the sketch medium can cause
      unintentional effects (for example, whiteboard markers can erase
      a little when sketch lines cross). We applied
      some <a href="http://scikit-image.org/docs/dev/auto_examples/applications/plot_morphology.html">morphological
      filtering</a> to compensate for the sketch imperfections. If
      applied too liberally, this type of filtering causes unwanted
      side effects. We will add more information on our approach
      later.
    </p>
    <figure>
      <img src="static/morphological_filtering.png" class="center-block img-responsive" alt="morphological filtering">
      <figcaption>
        <p class="text-muted">
          Morphological filtering can compensate for imperfections in
          a sketch, as demonstrated in this example. The original
          sketch (left) was done with a marker on white board. Notice
          how the vertical stroke erased a small part of the
          horizontal one. The binarized version of the sketch (middle)
          shows an unintentional gap between the strokes, but
          morphological filtering successfully closes the small gap
          (right).
        </p>
      </figcaption>
    </figure>
    <p>
      Compared to the binarization and segmentation, generating the
      output is a snap. With this final step, we’ve transformed a
      sketch into a png image where each geologic body is a different
      color. It’s ready to become a modelr synthetic section.</p>
    <h2 id="implementation">Implementation</h2>
    <p>
      Sketch2model was a working prototype by the end of the
      hackathon. It wasn’t the most robust algorithm, but it worked on
      a good proportion of our test images. We were excited enough to
      continue development after the hackathon. Evidently, we weren’t
      the only ones interested in further development because
      sketch2model came up on the February 17th episode
      of <a href="https://itunes.apple.com/us/podcast/undersampled-radio/id1087035286?mt=2">Undersampled
      Radio</a>.
    </p>
    <blockquote>
      <p>
        This is so cool. Draw something on a whiteboard and have a
        synthetic seismogram right on your iPad 5 seconds later. I
        mean, that’s magical.
      </p>
      <footer>Matt Hall <cite title="Undersampled Radio">Undersampled Radio Host</cite></footer>
    </blockquote>
    <p>
      The algorithm and web interface have progressed to the point
      that you can use it on your own images. For those interested in
      the nuts and bolts of the algorithm, sketch2model has a
      repository
      on <a href="https://github.com/mycarta/sketch2model">GitHub</a>. Information
      posted on these sites is scant right now, but we are working to
      add more information and documentation through time.
    </p>
  </div>
</div>
{% endblock %}
